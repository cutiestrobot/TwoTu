{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lie\n"
     ]
    }
   ],
   "source": [
    "#stem eliciter\n",
    "import nltk\n",
    "porter = nltk.PorterStemmer()\n",
    "print( porter.stem('lied'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['this', 'sentense', 'has', 'no', 'meaning']\n",
      "Help on function word_tokenize in module nltk.tokenize:\n",
      "\n",
      "word_tokenize(text, language='english', preserve_line=False)\n",
      "    Return a tokenized copy of *text*,\n",
      "    using NLTK's recommended word tokenizer\n",
      "    (currently an improved :class:`.TreebankWordTokenizer`\n",
      "    along with :class:`.PunktSentenceTokenizer`\n",
      "    for the specified language).\n",
      "    \n",
      "    :param text: text to split into words\n",
      "    :param text: str\n",
      "    :param language: the model name in the Punkt corpus\n",
      "    :type language: str\n",
      "    :param preserve_line: An option to keep the preserve the sentence and not sentence tokenize it.\n",
      "    :type preserver_line: bool\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#word token marker\n",
    "example = nltk.word_tokenize( \"this sentense has no meaning\" )\n",
    "print( type(example))\n",
    "print(example)\n",
    "help(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('this', 'DT'), ('sentense', 'NN'), ('has', 'VBZ'), ('no', 'DT'), ('meaning', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "examtag = nltk.pos_tag(example)\n",
    "print(examtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' fly', 'NP ')\n"
     ]
    }
   ],
   "source": [
    "mytoken = nltk.tag.str2tuple(' fly/NP ')\n",
    "print(mytoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('lala', 'NN'), ('啥', 'NP'), ('ygdfds', 'MM'), ('大傻x', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "mysent = 'lala/NN 啥/NP ygdfds/MM 大傻x/NN'\n",
    "mysplit = [\n",
    "    nltk.tag.str2tuple( word )\n",
    "    for word in mysent.split()\n",
    "]\n",
    "print(mysplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n",
      "Help on CategorizedTaggedCorpusReader in module nltk.corpus.reader.tagged object:\n",
      "\n",
      "class CategorizedTaggedCorpusReader(nltk.corpus.reader.api.CategorizedCorpusReader, TaggedCorpusReader)\n",
      " |  A reader for part-of-speech tagged corpora whose documents are\n",
      " |  divided into categories based on their file identifiers.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      CategorizedTaggedCorpusReader\n",
      " |      nltk.corpus.reader.api.CategorizedCorpusReader\n",
      " |      TaggedCorpusReader\n",
      " |      nltk.corpus.reader.api.CorpusReader\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *args, **kwargs)\n",
      " |      Initialize the corpus reader.  Categorization arguments\n",
      " |      (``cat_pattern``, ``cat_map``, and ``cat_file``) are passed to\n",
      " |      the ``CategorizedCorpusReader`` constructor.  The remaining arguments\n",
      " |      are passed to the ``TaggedCorpusReader``.\n",
      " |  \n",
      " |  paras(self, fileids=None, categories=None)\n",
      " |      :return: the given file(s) as a list of\n",
      " |          paragraphs, each encoded as a list of sentences, which are\n",
      " |          in turn encoded as lists of word strings.\n",
      " |      :rtype: list(list(list(str)))\n",
      " |  \n",
      " |  raw(self, fileids=None, categories=None)\n",
      " |      :return: the given file(s) as a single string.\n",
      " |      :rtype: str\n",
      " |  \n",
      " |  sents(self, fileids=None, categories=None)\n",
      " |      :return: the given file(s) as a list of\n",
      " |          sentences or utterances, each encoded as a list of word\n",
      " |          strings.\n",
      " |      :rtype: list(list(str))\n",
      " |  \n",
      " |  tagged_paras(self, fileids=None, categories=None, tagset=None)\n",
      " |      :return: the given file(s) as a list of\n",
      " |          paragraphs, each encoded as a list of sentences, which are\n",
      " |          in turn encoded as lists of ``(word,tag)`` tuples.\n",
      " |      :rtype: list(list(list(tuple(str,str))))\n",
      " |  \n",
      " |  tagged_sents(self, fileids=None, categories=None, tagset=None)\n",
      " |      :return: the given file(s) as a list of\n",
      " |          sentences, each encoded as a list of ``(word,tag)`` tuples.\n",
      " |      \n",
      " |      :rtype: list(list(tuple(str,str)))\n",
      " |  \n",
      " |  tagged_words(self, fileids=None, categories=None, tagset=None)\n",
      " |      :return: the given file(s) as a list of tagged\n",
      " |          words and punctuation symbols, encoded as tuples\n",
      " |          ``(word,tag)``.\n",
      " |      :rtype: list(tuple(str,str))\n",
      " |  \n",
      " |  words(self, fileids=None, categories=None)\n",
      " |      :return: the given file(s) as a list of words\n",
      " |          and punctuation symbols.\n",
      " |      :rtype: list(str)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      " |  \n",
      " |  categories(self, fileids=None)\n",
      " |      Return a list of the categories that are defined for this corpus,\n",
      " |      or for the file(s) if it is given.\n",
      " |  \n",
      " |  fileids(self, categories=None)\n",
      " |      Return a list of file identifiers for the files that make up\n",
      " |      this corpus, or that make up the given category(s) if specified.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from nltk.corpus.reader.api.CategorizedCorpusReader:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __unicode__ = __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  abspath(self, fileid)\n",
      " |      Return the absolute path for the given file.\n",
      " |      \n",
      " |      :type fileid: str\n",
      " |      :param fileid: The file identifier for the file whose path\n",
      " |          should be returned.\n",
      " |      :rtype: PathPointer\n",
      " |  \n",
      " |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      " |      Return a list of the absolute paths for all fileids in this corpus;\n",
      " |      or for the given list of fileids, if specified.\n",
      " |      \n",
      " |      :type fileids: None or str or list\n",
      " |      :param fileids: Specifies the set of fileids for which paths should\n",
      " |          be returned.  Can be None, for all fileids; a list of\n",
      " |          file identifiers, for a specified set of fileids; or a single\n",
      " |          file identifier, for a single file.  Note that the return\n",
      " |          value is always a list of paths, even if ``fileids`` is a\n",
      " |          single file identifier.\n",
      " |      \n",
      " |      :param include_encoding: If true, then return a list of\n",
      " |          ``(path_pointer, encoding)`` tuples.\n",
      " |      \n",
      " |      :rtype: list(PathPointer)\n",
      " |  \n",
      " |  citation(self)\n",
      " |      Return the contents of the corpus citation.bib file, if it exists.\n",
      " |  \n",
      " |  encoding(self, file)\n",
      " |      Return the unicode encoding for the given corpus file, if known.\n",
      " |      If the encoding is unknown, or if the given file should be\n",
      " |      processed using byte strings (str), then return None.\n",
      " |  \n",
      " |  ensure_loaded(self)\n",
      " |      Load this corpus (if it has not already been loaded).  This is\n",
      " |      used by LazyCorpusLoader as a simple method that can be used to\n",
      " |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      " |      do help(some_corpus).\n",
      " |  \n",
      " |  license(self)\n",
      " |      Return the contents of the corpus LICENSE file, if it exists.\n",
      " |  \n",
      " |  open(self, file)\n",
      " |      Return an open stream that can be used to read the given file.\n",
      " |      If the file's encoding is not None, then the stream will\n",
      " |      automatically decode the file's contents into unicode.\n",
      " |      \n",
      " |      :param file: The file identifier of the file to read.\n",
      " |  \n",
      " |  readme(self)\n",
      " |      Return the contents of the corpus README file, if it exists.\n",
      " |  \n",
      " |  unicode_repr = __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      " |  \n",
      " |  root\n",
      " |      The directory where this corpus is stored.\n",
      " |      \n",
      " |      :type: PathPointer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "print( brown.categories())\n",
    "help(brown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagLore = brown.tagged_words( fileids = ['cf01','cf03'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cf01',\n",
       " 'cf02',\n",
       " 'cf03',\n",
       " 'cf04',\n",
       " 'cf05',\n",
       " 'cf06',\n",
       " 'cf07',\n",
       " 'cf08',\n",
       " 'cf09',\n",
       " 'cf10',\n",
       " 'cf11',\n",
       " 'cf12',\n",
       " 'cf13',\n",
       " 'cf14',\n",
       " 'cf15',\n",
       " 'cf16',\n",
       " 'cf17',\n",
       " 'cf18',\n",
       " 'cf19',\n",
       " 'cf20',\n",
       " 'cf21',\n",
       " 'cf22',\n",
       " 'cf23',\n",
       " 'cf24',\n",
       " 'cf25',\n",
       " 'cf26',\n",
       " 'cf27',\n",
       " 'cf28',\n",
       " 'cf29',\n",
       " 'cf30',\n",
       " 'cf31',\n",
       " 'cf32',\n",
       " 'cf33',\n",
       " 'cf34',\n",
       " 'cf35',\n",
       " 'cf36',\n",
       " 'cf37',\n",
       " 'cf38',\n",
       " 'cf39',\n",
       " 'cf40',\n",
       " 'cf41',\n",
       " 'cf42',\n",
       " 'cf43',\n",
       " 'cf44',\n",
       " 'cf45',\n",
       " 'cf46',\n",
       " 'cf47',\n",
       " 'cf48']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.fileids(categories='lore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('In', 'IN'), ('American', 'JJ'), ('romance', 'NN'), ...]\n"
     ]
    }
   ],
   "source": [
    "print(tagLore)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
